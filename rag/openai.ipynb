{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook explores how to use OpenAI's <a href=\"https://platform.openai.com/docs/assistants/overview\">assistants</a> model to perform RAG using documents imported into a vector store. I wanted to put this in a notebook since the API documentation is incomplete and there are gaps in the APIs themselves (e.g., there is no way to enumerate threads).\n",
    "\n",
    "Here's an outline of the steps:\n",
    "1. Create a vector store and upload documents\n",
    "2. Create an assistant that uses the vector store\n",
    "3. Get a conversation thread\n",
    "4. Execture a chat on that thread using the assistant\n",
    "\n",
    "In each step, we first check if the objects have already been created before doing so again. This added some complexity for chat threads as OpenAI has no APIs to enumerate threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports needed for the rest of the script\n",
    "from sys import modules\n",
    "if \"openai\" not in modules:\n",
    "    print (\"Installing OpenAI\")\n",
    "    %pip install openai\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some global configuration variables\n",
    "CLIENT = OpenAI()                                   # The OpenAI client used in the rest of the notebook\n",
    "ASSISTANT_NAME = \"RAG assistant v 0.0.1\"            # Used to identify the assistant, as well as other objects related to it\n",
    "DIR = \"documents\"                                   # Directory where the RAG documents are stored\n",
    "SUPPORTED_EXTENSIONS = [\".pdf\", \".txt\", \".docx\"]    # Supported file extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a vector store and upload documents\n",
    "\n",
    "def get_vector_store(client, assistant_name):\n",
    "  \"\"\"Create a vector store if it doesn't already exist\"\"\"\n",
    "  vector_store_name = assistant_name + \" vector store\"\n",
    "\n",
    "  # If it was previously created, return it\n",
    "  vector_stores = client.beta.vector_stores.list()\n",
    "  for vector_store in vector_stores:\n",
    "    if vector_store.name == vector_store_name:\n",
    "      print (\"Using existing vector store\")\n",
    "      return vector_store\n",
    "  \n",
    "  # Else create it\n",
    "  print (\"Creating new vector store\")\n",
    "  return client.beta.vector_stores.create(name=vector_store_name)\n",
    "\n",
    "def upload_document(client, vector_store, filepath):\n",
    "  \"\"\"Upload a document to the vector store if it isn't already uploaded\"\"\"\n",
    "\n",
    "  # Check if the file is already uploaded\n",
    "  for existing_file in client.files.list(purpose=\"assistants\"):\n",
    "    if existing_file.filename == Path(filepath).name:\n",
    "      print (f\"{filepath} already uploaded\")\n",
    "      return\n",
    "\n",
    "  # Else upload it\n",
    "  print (f\"Uploading {filepath} and linking to the vector store\")\n",
    "  file = client.files.create(file=Path(filepath), purpose=\"assistants\")\n",
    "  client.beta.vector_stores.files.create_and_poll(file_id=file.id, vector_store_id=vector_store.id)\n",
    "\n",
    "def upload_documents (client, vector_store, dir, supported_extensions):\n",
    "  \"\"\"Upload all documents in a directory to the vector store\"\"\"\n",
    "  filepaths = [os.path.join(dir, filename) for filename in os.listdir(dir) if Path(filename).suffix in supported_extensions]\n",
    "  for filepath in filepaths:\n",
    "    upload_document(client, vector_store, Path(filepath))\n",
    "\n",
    "vector_store = get_vector_store(CLIENT, ASSISTANT_NAME)\n",
    "upload_documents(CLIENT, vector_store, DIR, SUPPORTED_EXTENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create an assistant that uses the vector store\n",
    "def get_assistant(client, assistant_name, vector_store):\n",
    "  \"\"\"Create the RAG assistant if it doesn't already exist\"\"\"\n",
    "\n",
    "  # If it was previously created, return it\n",
    "  assistants = client.beta.assistants.list()\n",
    "  for assistant in assistants:\n",
    "    if assistant.name == assistant_name:\n",
    "      print (\"Using existing assistant\")\n",
    "      return assistant\n",
    "\n",
    "  # Else create it\n",
    "  print (\"Creating new assistant\")\n",
    "  return client.beta.assistants.create(\n",
    "    name=assistant_name,\n",
    "    instructions=\"You are an assistant that will help answer questions about documents in a document library. \" + \\\n",
    "      \"You will always include references to both the document and section you used to answer a given query.\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "    model=\"gpt-4o\",\n",
    "  )\n",
    "\n",
    "\n",
    "assistant = get_assistant(CLIENT, ASSISTANT_NAME, vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a thread\n",
    "\n",
    "# OpenAI currently has no way to enumerate threads, so this is a hack to add local persistence\n",
    "# It also has no user-friendly way to identify a thread; only thread ID. So we create a wrapper class that stores name in metadata\n",
    "\n",
    "class OpenAIThreads:\n",
    "    _class_initialized = False      # Class initialization flag\n",
    "    _thread_ids = {}                # Dictionary to store mapping of thread names to IDs\n",
    "    _threads = {}                   # Dictionary to store mapping of thread IDs to objects\n",
    "    _file = \"openai_threads.json\"   # File to store persisted thread IDs and names\n",
    "    _client = OpenAI()              # OpenAI client\n",
    "\n",
    "    def _initialize_class():\n",
    "        \"\"\"Initialize the class if it hasn't been done yet\"\"\"\n",
    "        if not OpenAIThreads._class_initialized:\n",
    "            print (\"Initializing OpenAIThread class\")\n",
    "            if os.path.exists(OpenAIThreads._file):\n",
    "                with open(OpenAIThreads._file) as f:\n",
    "                    OpenAIThreads._thread_ids = json.load(f)\n",
    "            OpenAIThreads._class_initialized = True\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, name):\n",
    "        \"\"\"Either load an existing thread with the given name, or create a new one\"\"\"\n",
    "\n",
    "        # Initialize the class if it hasn't been done yet\n",
    "        cls._initialize_class()\n",
    "\n",
    "        # If the thread already exists, load it\n",
    "        if name in cls._thread_ids:\n",
    "            print (f\"Loading existing thread named '{name}'\")\n",
    "            id = cls._thread_ids[name]\n",
    "            if id in cls._threads:\n",
    "                return cls._threads[id]\n",
    "            thread = cls._client.beta.threads.retrieve(id)\n",
    "            cls._threads[id] = thread\n",
    "            return thread\n",
    "        \n",
    "        # Else create a new thread\n",
    "        thread = cls._client.beta.threads.create(metadata={\"name\": name})\n",
    "        cls._thread_ids[name] = thread.id\n",
    "        cls._threads[thread.id] = thread\n",
    "        with open(cls._file, \"w\") as f:\n",
    "            json.dump(cls._thread_ids, f)\n",
    "        return thread\n",
    "    \n",
    "    @classmethod\n",
    "    def delete(cls, name):\n",
    "        \"\"\"Delete a thread with the given name\"\"\"\n",
    "\n",
    "        # Initialize the class if it hasn't been done yet\n",
    "        cls._initialize_class()\n",
    "    \n",
    "        if not name in cls._thread_ids:\n",
    "            print (f\"No thread named '{name}'\")\n",
    "            return\n",
    "    \n",
    "        id = cls._thread_ids[name]\n",
    "        try:\n",
    "            cls._client.beta.threads.delete(id)\n",
    "        except Exception as e:\n",
    "            print (f\"Thread '{name}' not found in OpenAI\")\n",
    "        cls._thread_ids.pop(name, None)\n",
    "        cls._threads.pop(id, None)\n",
    "        with open(cls._file, \"w\") as f:\n",
    "            json.dump(cls._thread_ids, f)\n",
    "\n",
    "    @classmethod\n",
    "    def list_names(cls):\n",
    "        return cls._thread_ids.keys()\n",
    "\n",
    "def test_threads():\n",
    "    \"\"\"Test the threads class\"\"\"\n",
    "    while True:\n",
    "        print (\"Threads:\")\n",
    "        print (OpenAIThreads.list_names())\n",
    "        thread_name = input(\"Enter a thread name to add or remove, or press Enter to continue: \")\n",
    "        if thread_name == \"\":\n",
    "            break\n",
    "        if thread_name in OpenAIThreads.list_names():\n",
    "            OpenAIThreads.delete(thread_name)\n",
    "        else:\n",
    "            OpenAIThreads.get(thread_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Start a chat session on the thread\n",
    "\n",
    "# Get a fresh thread each time, deleting the old one if it exists\n",
    "OpenAIThreads.delete(ASSISTANT_NAME + \" thread\")\n",
    "thread = OpenAIThreads.get(ASSISTANT_NAME + \" thread\")\n",
    "\n",
    "# Create a streaming event handler to interact with the assistant\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "class EventHandler(AssistantEventHandler):\n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  #def on_tool_call_created(self, tool_call):\n",
    "  #  print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "# Start a chat session\n",
    "while True:\n",
    "    query = input(\"Enter a query, or press Enter to exit: \").strip()\n",
    "    if query == \"\":\n",
    "        break\n",
    "    message = CLIENT.beta.threads.messages.create(          # Add their query to the thread\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=query\n",
    "    )\n",
    "    with CLIENT.beta.threads.runs.stream(                   # Run the assistant on the thread\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        event_handler=EventHandler()\n",
    "    ) as stream:\n",
    "        stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
